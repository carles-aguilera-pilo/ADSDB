{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "716b987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Limpieza completada:\n",
      "  Original: 798 filas\n",
      "  Limpio: 757 filas\n",
      "  Eliminadas: 41 filas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_json(\"hf://datasets/Moaaz55/skin_cancer_questions_answers/dataset.json\", lines=True)\n",
    "\n",
    "def limpiar_dataset(df, columna='Answer'):\n",
    "    # Convertir a string y limpiar\n",
    "    df_temp = df.copy()\n",
    "    df_temp[columna] = df_temp[columna].astype(str)\n",
    "    \n",
    "    # Filtrar respuestas vÃ¡lidas\n",
    "    df_limpio = df_temp[\n",
    "        df_temp[columna].notna() & \n",
    "        (df_temp[columna].str.strip() != '') &\n",
    "        (df_temp[columna].str.strip() != 'nan') &\n",
    "        (df_temp[columna].str.strip() != 'None') &\n",
    "        (df_temp[columna].str.strip() != 'null') &\n",
    "        (df_temp[columna].str.len() > 10)  # MÃ­nimo 10 caracteres\n",
    "    ]\n",
    "    \n",
    "    print(f\"âœ… Limpieza completada:\")\n",
    "    print(f\"  Original: {len(df)} filas\")\n",
    "    print(f\"  Limpio: {len(df_limpio)} filas\")\n",
    "    print(f\"  Eliminadas: {len(df) - len(df_limpio)} filas\")\n",
    "    \n",
    "    return df_limpio\n",
    "\n",
    "\n",
    "df = limpiar_dataset(df)\n",
    "df = df.sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e3bf8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Funciones de conversiÃ³n a audio cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# CONVERTIR LAS RESPUESTAS A AUDIO CON LA LIBRERIA TTS\n",
    "import os\n",
    "import io\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from gtts import gTTS\n",
    "from mutagen.mp3 import MP3\n",
    "\n",
    "# PARÃMETROS DE CONFIGURACIÃ“N\n",
    "OUT_DIR = \"output_audio\"\n",
    "LANG = \"es\"\n",
    "TEXT_COL = \"Answer\"\n",
    "\n",
    "# CREAR DIRECTORIOS DE AUDIO Y METADATA\n",
    "def ensure_dirs(root):\n",
    "    audio_dir = os.path.join(root, \"audio\")\n",
    "    metadata_dir = os.path.join(root, \"metadata\")\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "    os.makedirs(metadata_dir, exist_ok=True)\n",
    "    return audio_dir, metadata_dir\n",
    "\n",
    "# FUNCIÃ“N PARA GENERAR HASH MD5 (EVITAR DUPLICADOS)\n",
    "def md5(s: str) -> str:\n",
    "    return hashlib.md5(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# CONVERTIR TEXTO A BYTES DE AUDIO\n",
    "def tts_bytes(text: str, lang: str) -> bytes:\n",
    "    buf = io.BytesIO()\n",
    "    gTTS(text=text, lang=lang).write_to_fp(buf)\n",
    "    buf.seek(0)\n",
    "    return buf.read()\n",
    "\n",
    "# OBTENER DURACIÃ“N DEL MP3\n",
    "def mp3_duration(b: bytes):\n",
    "    try:\n",
    "        return float(MP3(io.BytesIO(b)).info.length)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# FUNCIÃ“N PRINCIPAL PARA CONVERTIR RESPUESTAS A AUDIO\n",
    "def answers_to_audio(df: pd.DataFrame):\n",
    "    audio_dir, meta_dir = ensure_dirs(OUT_DIR)\n",
    "    df_out = df.copy()\n",
    "\n",
    "    # AÃ±adir columnas para metadatos de audio\n",
    "    df_out[\"Answer_audio_relpath\"] = None\n",
    "    df_out[\"Answer_duration_sec\"] = None\n",
    "    df_out[\"Answer_size_bytes\"] = None\n",
    "    df_out[\"Answer_text_md5\"] = None\n",
    "\n",
    "    total = len(df_out)\n",
    "    for i, text in enumerate(df_out[TEXT_COL].astype(str)):\n",
    "        if not text.strip():\n",
    "            continue\n",
    "\n",
    "        h = md5(text)\n",
    "        filename = f\"answer_{h}.mp3\"\n",
    "        abspath = os.path.join(audio_dir, filename)\n",
    "        relpath = os.path.join(\"audio\", filename)\n",
    "\n",
    "        # Solo generar si no existe\n",
    "        if not os.path.exists(abspath):\n",
    "            mp3 = tts_bytes(text, LANG)\n",
    "            with open(abspath, \"wb\") as f:\n",
    "                f.write(mp3)\n",
    "            size = len(mp3)\n",
    "            dur = mp3_duration(mp3)\n",
    "        else:\n",
    "            with open(abspath, \"rb\") as f:\n",
    "                data = f.read()\n",
    "            size = len(data)\n",
    "            dur = mp3_duration(data)\n",
    "\n",
    "        df_out.at[i, \"Answer_audio_relpath\"] = relpath.replace(\"\\\\\", \"/\")\n",
    "        df_out.at[i, \"Answer_duration_sec\"] = dur\n",
    "        df_out.at[i, \"Answer_size_bytes\"] = size\n",
    "        df_out.at[i, \"Answer_text_md5\"] = h\n",
    "\n",
    "        if (i+1) % 50 == 0 or i+1 == total:\n",
    "            print(f\"[{i+1}/{total}] {relpath} ({dur:.2f}s)\")\n",
    "\n",
    "    # Guardar dataset enriquecido\n",
    "    today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "    out_latest = os.path.join(meta_dir, \"answers_dataset-latest.parquet\")\n",
    "    out_dated = os.path.join(meta_dir, f\"answers_dataset-{today}.parquet\")\n",
    "\n",
    "    df_out.to_parquet(out_latest, index=False)\n",
    "    df_out.to_parquet(out_dated, index=False)\n",
    "\n",
    "    print(\"\\nâœ… Listo\")\n",
    "    print(\"Audios â†’\", os.path.abspath(audio_dir))\n",
    "    print(\"Nuevo dataset â†’\", out_latest)\n",
    "    return df_out\n",
    "\n",
    "print(\"âœ… Funciones de conversiÃ³n a audio cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee0f5f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/100] audio/answer_052634ca40f8ef4a37421a33775ca14d.mp3 (3.79s)\n",
      "[100/100] audio/answer_3c4ffb08352ccac2ed9478f99c0c2418.mp3 (3.55s)\n",
      "\n",
      "âœ… Listo\n",
      "Audios â†’ /Users/carlesaguilera/Desktop/ADSDB/output_audio/audio\n",
      "Nuevo dataset â†’ output_audio/metadata/answers_dataset-latest.parquet\n"
     ]
    }
   ],
   "source": [
    "df_amb_audio = answers_to_audio(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70056f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š EstadÃ­sticas:\n",
      "  Total respuestas: 183\n",
      "  Audios generados: 100\n",
      "  Respuestas vacÃ­as: 83\n",
      "  Tasa de Ã©xito: 54.6%\n"
     ]
    }
   ],
   "source": [
    "df_amb_audio['Answer_audio_relpath']\n",
    "total_respuestas = len(df_amb_audio)\n",
    "audios_generados = df_amb_audio['Answer_audio_relpath'].notna().sum()\n",
    "respuestas_vacias = df_amb_audio['Answer_audio_relpath'].isna().sum()\n",
    "\n",
    "print(f\"ðŸ“Š EstadÃ­sticas:\")\n",
    "print(f\"  Total respuestas: {total_respuestas}\")\n",
    "print(f\"  Audios generados: {audios_generados}\")\n",
    "print(f\"  Respuestas vacÃ­as: {respuestas_vacias}\")\n",
    "print(f\"  Tasa de Ã©xito: {audios_generados/total_respuestas*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e61c1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "\n",
    "model_id = \"abaryan/DrDiag_qwen2vl_Ham10000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8012/8012 [00:05<00:00, 1389.05 examples/s]\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2003/2003 [00:03<00:00, 522.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"abaryan/ham10000_bbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7b378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x450 at 0x1205FF400>\n",
      "{'lesion_id': 'HAM_0007418', 'image_id': 'ISIC_0031372', 'diagnosis': 'df', 'dx_type': 'consensus', 'age': 50.0, 'sex': 'male', 'localization': 'lower extremity', 'bbox': [235.0, 175.0, 368.0, 264.0], 'area_coverage': 0.03166111186146736}\n",
      "---\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x450 at 0x1205FCDC0>\n",
      "{'lesion_id': 'HAM_0004785', 'image_id': 'ISIC_0030788', 'diagnosis': 'nv', 'dx_type': 'follow_up', 'age': 60.0, 'sex': 'male', 'localization': 'back', 'bbox': [58.0, 0.0, 496.0, 420.0], 'area_coverage': 0.502837061882019}\n",
      "---\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x450 at 0x1205FC520>\n",
      "{'lesion_id': 'HAM_0004585', 'image_id': 'ISIC_0032881', 'diagnosis': 'nv', 'dx_type': 'consensus', 'age': 55.0, 'sex': 'male', 'localization': 'unknown', 'bbox': [189.0, 131.0, 357.0, 297.0], 'area_coverage': 0.07799629867076874}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# HERE WE'RE GOING TO GET THE DATA FROM THE DATA SET OF HAM10000.\n",
    "\n",
    "# THE PREPARATION CONSISTS OF GETTING THE IMAGES AND THE TABULAR DATA AND SPLIT THEM TO DIFFERENT LOCATIONS IN MINIO.\n",
    "\n",
    "data = ds['train']  #HERE WE GET THE DATA FROM THE DATA SET, IN THAT CASE DUE TO THE DATASET HAVE TO PARTS.\n",
    "                    #ONE FROM THE TRAIN AND THE OTHER FROM THE TEST, WE'LL USE THE TRAIN.\n",
    "\n",
    "# NOW WE GET THE IMAGES AND THE TABULAR DATA.\n",
    "images = data['image'] # HERE WE GET THE IMAGES FROM THE DATASET.\n",
    "tabular_data = data.remove_columns('image') # HERE WE GET THE TABULAR DATA FROM THE DATASET.\n",
    "\n",
    "# NOW WE PRINT THE FIRST 3 IMAGES AND THE FIRST 3 ROWS OF THE TABULAR DATA.\n",
    "\n",
    "# NOW WE'RE GOING TO PUSH THE DATA TO MINIO.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
