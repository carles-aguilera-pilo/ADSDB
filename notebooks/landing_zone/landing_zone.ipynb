{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee10ef0b",
   "metadata": {},
   "source": [
    "# Landing Zone\n",
    "\n",
    "This notebook contains the different steps involved steps in the the extraction of data and its storage in the landing zone of our data management pipeline. Particularly, the following scripts are responsible of the following tasks:\n",
    "1. Environment setup, such as the preparation of the data lake (based on MinIO)\n",
    "2. Obtaining of data from datasources\n",
    "3. Raw data storaging into the temporal landing \n",
    "4. Data shipment from temporal landing to persistent landing\n",
    "\n",
    "## Environment Setup\n",
    "Before starting to get data from datasources it is needed to prepare our temporal landing. As said before, we will be using MinIO, an S3-compatible object storage implementation, as a data lake to store data as it comes. Before continuing, ensure that a MinIO instance is up and running, which can be done easily with Docker Compose (see the main [README](../../README.md) file for more information).\n",
    "\n",
    "First of all, we will connect to the MinIo instance, create a bucket for the landing zone and a subfolder that will correspond to the temporal landing. To interact with MinIO programatically we will use the [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-creating-buckets.html) Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf9be1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'landing-zone' already exists\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "access_key_id = \"minioadmin\"\n",
    "secret_access_key = \"minioadmin\"\n",
    "\n",
    "minio_url = 'http://localhost:9000'\n",
    "\n",
    "minio_client = boto3.client('s3',\n",
    "    aws_access_key_id=access_key_id,\n",
    "    aws_secret_access_key=secret_access_key,\n",
    "    endpoint_url=minio_url\n",
    ")\n",
    "\n",
    "bucket = \"landing-zone\"\n",
    "try:\n",
    "    minio_client.head_bucket(Bucket=bucket)\n",
    "    print(f\"Bucket '{bucket}' already exists\")\n",
    "except ClientError:\n",
    "    print(f\"Creando bucket: {bucket}\")\n",
    "    minio_client.create_bucket(Bucket=bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "716b987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Limpieza completada:\n",
      "  Original: 798 filas\n",
      "  Limpio: 757 filas\n",
      "  Eliminadas: 41 filas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_json(\"hf://datasets/Moaaz55/skin_cancer_questions_answers/dataset.json\", lines=True)\n",
    "\n",
    "def limpiar_dataset(df, columna='Answer'):\n",
    "    # Convertir a string y limpiar\n",
    "    df_temp = df.copy()\n",
    "    df_temp[columna] = df_temp[columna].astype(str)\n",
    "    \n",
    "    # filter valid answers.\n",
    "    df_limpio = df_temp[\n",
    "        df_temp[columna].notna() &\n",
    "        (df_temp[columna].str.strip() != '') &\n",
    "        (df_temp[columna].str.strip() != 'nan') &\n",
    "        (df_temp[columna].str.strip() != 'None') &\n",
    "        (df_temp[columna].str.strip() != 'null') &\n",
    "        (df_temp[columna].str.len() > 10)  # Mínimo 10 caracteres\n",
    "    ]\n",
    "    \n",
    "    print(f\" Limpieza completada:\")\n",
    "    print(f\"  Original: {len(df)} filas\")\n",
    "    print(f\"  Limpio: {len(df_limpio)} filas\")\n",
    "    print(f\"  Eliminadas: {len(df) - len(df_limpio)} filas\")\n",
    "    \n",
    "    return df_limpio\n",
    "\n",
    "\n",
    "df = limpiar_dataset(df)\n",
    "df = df.sample(n=100, random_state=42)\n",
    "df_text = df\n",
    "df_text = df.apply(lambda row: f\"Q: {row['Question']}\\nA: {row['Answer']}\\n\", axis=1)\n",
    "df_text\n",
    "with open(\"preguntas_respuestas.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(df_text.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3bf8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Funciones de conversión a audio cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# CONVERT THE TEXT TO AUDIO WITH THE TT'S LIBRARY\n",
    "import os\n",
    "import io\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from gtts import gTTS\n",
    "from mutagen.mp3 import MP3\n",
    "\n",
    "# CONFIGRATION PARAMETERS\n",
    "OUT_DIR = \"output_audio\"\n",
    "LANG = \"es\"\n",
    "TEXT_COL = \"Answer\"\n",
    "\n",
    "# CREATE AUDIO AND METADATA DIRECTORIES\n",
    "def ensure_dirs(root):\n",
    "    audio_dir = os.path.join(root, \"audio\")\n",
    "    metadata_dir = os.path.join(root, \"metadata\")\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "    os.makedirs(metadata_dir, exist_ok=True)\n",
    "    return audio_dir, metadata_dir\n",
    "\n",
    "# FUNCTION TO GENERATE MD5 HASH (AVOID DUPLICATES)\n",
    "def md5(s: str) -> str:\n",
    "    return hashlib.md5(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# CONVERT TEXT TO AUDIO BYTES\n",
    "def tts_bytes(text: str, lang: str) -> bytes:\n",
    "    buf = io.BytesIO()\n",
    "    gTTS(text=text, lang=lang).write_to_fp(buf)\n",
    "    buf.seek(0)\n",
    "    return buf.read()\n",
    "\n",
    "# GET MP3 DURATION\n",
    "def mp3_duration(b: bytes):\n",
    "    try:\n",
    "        return float(MP3(io.BytesIO(b)).info.length)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# MAIN FUNCTION TO CONVERT ANSWERS TO AUDIO\n",
    "def answers_to_audio(df: pd.DataFrame):\n",
    "    audio_dir, meta_dir = ensure_dirs(OUT_DIR)\n",
    "    df_out = df.copy()\n",
    "\n",
    "    # Add columns for audio metadata\n",
    "    df_out[\"Answer_audio_relpath\"] = None\n",
    "    df_out[\"Answer_duration_sec\"] = None\n",
    "    df_out[\"Answer_size_bytes\"] = None\n",
    "    df_out[\"Answer_text_md5\"] = None\n",
    "\n",
    "    total = len(df_out)\n",
    "    for i, text in enumerate(df_out[TEXT_COL].astype(str)):\n",
    "        if not text.strip():\n",
    "            continue\n",
    "\n",
    "        h = md5(text)\n",
    "        filename = f\"answer_{h}.mp3\"\n",
    "        abspath = os.path.join(audio_dir, filename)\n",
    "        relpath = os.path.join(\"audio\", filename)\n",
    "\n",
    "        # Only generate if it doesn't exist\n",
    "        if not os.path.exists(abspath):\n",
    "            mp3 = tts_bytes(text, LANG)\n",
    "            with open(abspath, \"wb\") as f:\n",
    "                f.write(mp3)\n",
    "            size = len(mp3)\n",
    "            dur = mp3_duration(mp3)\n",
    "        else:\n",
    "            with open(abspath, \"rb\") as f:\n",
    "                data = f.read()\n",
    "            size = len(data)\n",
    "            dur = mp3_duration(data)\n",
    "\n",
    "        df_out.at[i, \"Answer_audio_relpath\"] = relpath.replace(\"\\\\\", \"/\")\n",
    "        df_out.at[i, \"Answer_duration_sec\"] = dur\n",
    "        df_out.at[i, \"Answer_size_bytes\"] = size\n",
    "        df_out.at[i, \"Answer_text_md5\"] = h\n",
    "\n",
    "        if (i+1) % 50 == 0 or i+1 == total:\n",
    "            print(f\"[{i+1}/{total}] {relpath} ({dur:.2f}s)\")\n",
    "\n",
    "    # Save enriched dataset\n",
    "    today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "    out_latest = os.path.join(meta_dir, \"answers_dataset-latest.parquet\")\n",
    "    out_dated = os.path.join(meta_dir, f\"answers_dataset-{today}.parquet\")\n",
    "\n",
    "    df_out.to_parquet(out_latest, index=False)\n",
    "    df_out.to_parquet(out_dated, index=False)\n",
    "\n",
    "    print(\"\\n Listo\")\n",
    "    print(\"Audios →\", os.path.abspath(audio_dir))\n",
    "    print(\"Nuevo dataset →\", out_latest)\n",
    "    return df_out\n",
    "\n",
    "print(\" Funciones de conversión a audio cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee0f5f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/100] audio/answer_052634ca40f8ef4a37421a33775ca14d.mp3 (3.79s)\n",
      "[100/100] audio/answer_3c4ffb08352ccac2ed9478f99c0c2418.mp3 (3.55s)\n",
      "\n",
      " Listo\n",
      "Audios → /Users/carlesaguilera/Desktop/ADSDB/notebooks/landing_zone/output_audio/audio\n",
      "Nuevo dataset → output_audio/metadata/answers_dataset-latest.parquet\n"
     ]
    }
   ],
   "source": [
    "df_amb_audio = answers_to_audio(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c9ce7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97    audio/answer_04fa859c680f344018eade336e06fef5.mp3\n",
       "78    audio/answer_1f8e49d8f875f9c122ef1c8fce7e9682.mp3\n",
       "54    audio/answer_58d0f1f405489d61fbf7cf9eb7936942.mp3\n",
       "39    audio/answer_46bbf2aaac121735d55561672a1d228a.mp3\n",
       "66    audio/answer_e08a77c07bc54b170cb7cbf96b8fd0ac.mp3\n",
       "33    audio/answer_c0d2ee7dffc8995b2719e6f57bc69bff.mp3\n",
       "77    audio/answer_22138b57e53bc9f98ea9f00f2c3a2e09.mp3\n",
       "10    audio/answer_e4ad6acc62ab285c11023019a6f8072a.mp3\n",
       "81    audio/answer_676ccac3f2890a63d633a797fe7f831d.mp3\n",
       "31    audio/answer_03c43a00e72c214fe7d11957835e4445.mp3\n",
       "65    audio/answer_5b3af1fe3cb2959b0abeb4d4711b2bb7.mp3\n",
       "76    audio/answer_45a2d7224bf20a670e1216ae9abce958.mp3\n",
       "72    audio/answer_3c91257eeb46e6e23997462e35cb29d2.mp3\n",
       "63    audio/answer_55dfef06dbc3f01fb0f6156d00a7afaa.mp3\n",
       "49    audio/answer_052634ca40f8ef4a37421a33775ca14d.mp3\n",
       "7     audio/answer_49737cdeb9605126ae4a323d5a946c88.mp3\n",
       "23    audio/answer_cb21df667b30b341660a32aee586f632.mp3\n",
       "Name: Answer_audio_relpath, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amb_audio\n",
    "# LET'S CLEAN THE DATA, AND FINALLY TAKE THE ONES THAT ARE REALLY COMPLETED.\n",
    "df_amb_audio = df_amb_audio.dropna()\n",
    "df_amb_audio\n",
    "\n",
    "# PRERPARE AUDIOS FOR THE PUSH TO MINIO. \n",
    "\n",
    "audio = df_amb_audio[\"Answer_audio_relpath\"]\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70056f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Estadísticas:\n",
      "  Total respuestas: 17\n",
      "  Audios generados: 17\n",
      "  Respuestas vacías: 0\n",
      "  Tasa de éxito: 100.0%\n"
     ]
    }
   ],
   "source": [
    "df_amb_audio['Answer_audio_relpath']\n",
    "total_respuestas = len(df_amb_audio)\n",
    "audios_generados = df_amb_audio['Answer_audio_relpath'].notna().sum()\n",
    "respuestas_vacias = df_amb_audio['Answer_audio_relpath'].isna().sum()\n",
    "\n",
    "print(f\"📊 Statistics:\")\n",
    "print(f\"  Total respuestas: {total_respuestas}\")\n",
    "print(f\"  Audios generados: {audios_generados}\")\n",
    "print(f\"  Respuestas vacías: {respuestas_vacias}\")\n",
    "print(f\"  Tasa de éxito: {audios_generados/total_respuestas*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "model_id = \"abaryan/DrDiag_qwen2vl_Ham10000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3994a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"abaryan/ham10000_bbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3a7b378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column([<PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x450 at 0x1300B1540>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x450 at 0x1300B15D0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x450 at 0x1300B1600>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x450 at 0x1300B1630>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x450 at 0x1300B14E0>])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# HERE WE'RE GOING TO GET THE DATA FROM THE DATA SET OF HAM10000.\n",
    "\n",
    "# THE PREPARATION CONSISTS OF GETTING THE IMAGES AND THE TABULAR DATA AND SPLIT THEM TO DIFFERENT LOCATIONS IN MINIO.\n",
    "\n",
    "data = ds['train']  #HERE WE GET THE DATA FROM THE DATA SET, IN THAT CASE DUE TO THE DATASET HAVE TO PARTS.\n",
    "                    #ONE FROM THE TRAIN AND THE OTHER FROM THE TEST, WE'LL USE THE TRAIN.\n",
    "# NOW WE GET THE IMAGES AND THE TABULAR DATA.\n",
    "images = data['image'] # HERE WE GET THE IMAGES FROM THE DATASET.\n",
    "tabular_data = data.remove_columns('image') # HERE WE GET THE TABULAR DATA FROM THE DATASET.\n",
    "\n",
    "# NOW WE PRINT THE FIRST 3 IMAGES AND THE FIRST 3 ROWS OF THE TABULAR DATA.\n",
    "\n",
    "# NOW WE'RE GOING TO PUSH THE DATA TO MINIO.\n",
    "images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc545045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente MinIO configurado correctamente\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# DATA LAKE EN MINIO - ESTRUCTURA ORGANIZADA\n",
    "# =====================================================\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "minio_client = boto3.client('s3',\n",
    "    aws_access_key_id=access_key_id,\n",
    "    aws_secret_access_key=secret_access_key,\n",
    "    endpoint_url=minio_url\n",
    ")\n",
    "\n",
    "print(\"Cliente MinIO configurado correctamente\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a852844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'landing-zone' ya existe\n"
     ]
    }
   ],
   "source": [
    "bucket = \"landing-zone\"\n",
    "try:\n",
    "    minio_client.head_bucket(Bucket=bucket)\n",
    "    print(f\"Bucket '{bucket}' already exists.\")\n",
    "except ClientError:\n",
    "    print(f\"Creando bucket: {bucket}\")\n",
    "    minio_client.create_bucket(Bucket=bucket)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6da3be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_client.upload_file(Filename=\"preguntas_respuestas.txt\", Bucket= bucket, Key = \"preguntas_respuestas_bucket.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc732a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data = tabular_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e78f725f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '186CEDD4BB4EA361',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '0',\n",
       "   'etag': '\"ec7d7119b1ed058dbb28471f7070c9e4\"',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-checksum-crc32': '+iWcPg==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '186CEDD4BB4EA361',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '1015',\n",
       "   'x-ratelimit-remaining': '1015',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Thu, 09 Oct 2025 20:50:52 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"ec7d7119b1ed058dbb28471f7070c9e4\"',\n",
       " 'ChecksumCRC32': '+iWcPg==',\n",
       " 'ChecksumType': 'FULL_OBJECT'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tabular_data = tabular_data.to_csv(index=False).encode(\"utf-8\")\n",
    "\n",
    "minio_client.put_object( \n",
    "    Bucket = \"landing-zone\",\n",
    "    Key=\"tabular_data.csv\",\n",
    "    Body = io.BytesIO(tabular_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05288a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    img_bytes = io.BytesIO()\n",
    "    img.save(img_bytes, format=\"PNG\") \n",
    "    img_bytes.seek(0)\n",
    "\n",
    "    image_name = f\"imagen_{i}.png\"\n",
    "\n",
    "    minio_client.put_object(\n",
    "        Bucket=\"landing-zone\",\n",
    "        Key=f\"{image_name}\",\n",
    "        Body=img_bytes\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77f72a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'landing-zone' ja existeix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pujant àudios: 100%|██████████| 17/17 [00:00<00:00, 130.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tots els àudios pujats correctament a MinIO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "bucket = \"landing-zone\"\n",
    "\n",
    "\n",
    "try:\n",
    "    minio_client.head_bucket(Bucket=bucket)\n",
    "    print(f\"Bucket '{bucket}' ja existeix\")\n",
    "except:\n",
    "    print(f\"Creant bucket: {bucket}\")\n",
    "    minio_client.create_bucket(Bucket=bucket)\n",
    "\n",
    "# Iterar sobre cada ruta d'àudio del DataFrame\n",
    "for path in tqdm(df_amb_audio[\"Answer_audio_relpath\"], desc=\"Pujant àudios\"):\n",
    "    if os.path.exists(path):  # comprovar que el fitxer realment existeix\n",
    "        audio_name = os.path.basename(path)  # ex: answer_04fa859c6....mp3\n",
    "\n",
    "        # Pujar l'àudio directament al bucket\n",
    "        minio_client.upload_file(\n",
    "            Filename=path,\n",
    "            Bucket=bucket,\n",
    "            Key=f\"{audio_name}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Fitxer no trobat: {path}\")\n",
    "\n",
    "print(\"Tots els àudios pujats correctament a MinIO\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
