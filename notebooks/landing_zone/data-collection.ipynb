{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9adf352d",
   "metadata": {},
   "source": [
    "# Obtaining the data from datasources\n",
    "\n",
    "The first part of this project is to obtain the data from the different datsources we have chosen. Also, there are some datasources that for purposes of this project, we have created ourselves. In this notebook we will explain how the data is created, if needed, and how the data is collected from the different data sources. Specifically, we will obtain the data from three different data sources:\n",
    "1. [huggingface dataset](https://huggingface.co/datasets/Moaaz55/skin_cancer_questions_answers). This dataset is used for **joel pots explicar aqui**\n",
    "2. Self made audio dataset. This dataset is used for ...\n",
    "3. Wikipedia web scrapping information. This dataset is used for...\n",
    "\n",
    "In the next sections, we will discuss how the data is obtained to further insert them into the first zone of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a733d14",
   "metadata": {},
   "source": [
    "## Huggingface Dataset\n",
    "\n",
    "Explicar huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1191422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"abaryan/ham10000_bbox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed3300",
   "metadata": {},
   "source": [
    "## Self made audio dataset\n",
    "\n",
    "Explicar self made audio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e45004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_json(\"hf://datasets/Moaaz55/skin_cancer_questions_answers/dataset.json\", lines=True)\n",
    "\n",
    "def limpiar_dataset(df, columna='Answer'):\n",
    "    # Convertir a string y limpiar\n",
    "    df_temp = df.copy()\n",
    "    df_temp[columna] = df_temp[columna].astype(str)\n",
    "    \n",
    "    # filter valid answers.\n",
    "    df_limpio = df_temp[\n",
    "        df_temp[columna].notna() &\n",
    "        (df_temp[columna].str.strip() != '') &\n",
    "        (df_temp[columna].str.strip() != 'nan') &\n",
    "        (df_temp[columna].str.strip() != 'None') &\n",
    "        (df_temp[columna].str.strip() != 'null') &\n",
    "        (df_temp[columna].str.len() > 10)  # Mínimo 10 caracteres\n",
    "    ]\n",
    "    \n",
    "    print(f\" Limpieza completada:\")\n",
    "    print(f\"  Original: {len(df)} filas\")\n",
    "    print(f\"  Limpio: {len(df_limpio)} filas\")\n",
    "    print(f\"  Eliminadas: {len(df) - len(df_limpio)} filas\")\n",
    "    \n",
    "    return df_limpio\n",
    "\n",
    "\n",
    "df = limpiar_dataset(df)\n",
    "df = df.sample(n=100, random_state=42)\n",
    "df_text = df\n",
    "df_text = df.apply(lambda row: f\"Q: {row['Question']}\\nA: {row['Answer']}\\n\", axis=1)\n",
    "df_text\n",
    "with open(\"../output/dataset1_preguntes.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(df_text.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f535d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT THE TEXT TO AUDIO WITH THE TT'S LIBRARY\n",
    "import os\n",
    "import io\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from gtts import gTTS\n",
    "from mutagen.mp3 import MP3\n",
    "\n",
    "# CONFIGRATION PARAMETERS\n",
    "OUT_DIR = \"output_audio\"\n",
    "LANG = \"es\"\n",
    "TEXT_COL = \"Answer\"\n",
    "\n",
    "# CREATE AUDIO AND METADATA DIRECTORIES\n",
    "def ensure_dirs(root):\n",
    "    audio_dir = os.path.join(root, \"audio\")\n",
    "    metadata_dir = os.path.join(root, \"metadata\")\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "    os.makedirs(metadata_dir, exist_ok=True)\n",
    "    return audio_dir, metadata_dir\n",
    "\n",
    "# FUNCTION TO GENERATE MD5 HASH (AVOID DUPLICATES)\n",
    "def md5(s: str) -> str:\n",
    "    return hashlib.md5(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# CONVERT TEXT TO AUDIO BYTES\n",
    "def tts_bytes(text: str, lang: str) -> bytes:\n",
    "    buf = io.BytesIO()\n",
    "    gTTS(text=text, lang=lang).write_to_fp(buf)\n",
    "    buf.seek(0)\n",
    "    return buf.read()\n",
    "\n",
    "# GET MP3 DURATION\n",
    "def mp3_duration(b: bytes):\n",
    "    try:\n",
    "        return float(MP3(io.BytesIO(b)).info.length)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# MAIN FUNCTION TO CONVERT ANSWERS TO AUDIO\n",
    "def answers_to_audio(df: pd.DataFrame):\n",
    "    audio_dir, meta_dir = ensure_dirs(OUT_DIR)\n",
    "    df_out = df.copy()\n",
    "\n",
    "    # Add columns for audio metadata\n",
    "    df_out[\"Answer_audio_relpath\"] = None\n",
    "    df_out[\"Answer_duration_sec\"] = None\n",
    "    df_out[\"Answer_size_bytes\"] = None\n",
    "    df_out[\"Answer_text_md5\"] = None\n",
    "\n",
    "    total = len(df_out)\n",
    "    for i, text in enumerate(df_out[TEXT_COL].astype(str)):\n",
    "        if not text.strip():\n",
    "            continue\n",
    "\n",
    "        h = md5(text)\n",
    "        filename = f\"answer_{h}.mp3\"\n",
    "        abspath = os.path.join(audio_dir, filename)\n",
    "        relpath = os.path.join(\"audio\", filename)\n",
    "\n",
    "        # Only generate if it doesn't exist\n",
    "        if not os.path.exists(abspath):\n",
    "            mp3 = tts_bytes(text, LANG)\n",
    "            with open(abspath, \"wb\") as f:\n",
    "                f.write(mp3)\n",
    "            size = len(mp3)\n",
    "            dur = mp3_duration(mp3)\n",
    "        else:\n",
    "            with open(abspath, \"rb\") as f:\n",
    "                data = f.read()\n",
    "            size = len(data)\n",
    "            dur = mp3_duration(data)\n",
    "\n",
    "        df_out.at[i, \"Answer_audio_relpath\"] = relpath.replace(\"\\\\\", \"/\")\n",
    "        df_out.at[i, \"Answer_duration_sec\"] = dur\n",
    "        df_out.at[i, \"Answer_size_bytes\"] = size\n",
    "        df_out.at[i, \"Answer_text_md5\"] = h\n",
    "\n",
    "        if (i+1) % 50 == 0 or i+1 == total:\n",
    "            print(f\"[{i+1}/{total}] {relpath} ({dur:.2f}s)\")\n",
    "\n",
    "    # Save enriched dataset\n",
    "    today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "    out_latest = os.path.join(meta_dir, \"answers_dataset-latest.parquet\")\n",
    "    out_dated = os.path.join(meta_dir, f\"answers_dataset-{today}.parquet\")\n",
    "\n",
    "    df_out.to_parquet(out_latest, index=False)\n",
    "    df_out.to_parquet(out_dated, index=False)\n",
    "\n",
    "    print(\"\\n Listo\")\n",
    "    print(\"Audios →\", os.path.abspath(audio_dir))\n",
    "    print(\"Nuevo dataset →\", out_latest)\n",
    "    return df_out\n",
    "\n",
    "print(\" Funciones de conversión a audio cargadas correctamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
