{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9adf352d",
   "metadata": {},
   "source": [
    "# Obtaining the data from datasources\n",
    "\n",
    "The first part of this project is to obtain the data from the different datsources we have chosen. Also, there are some datasources that for purposes of this project, we have created ourselves. In this notebook we will explain how the data is created, if needed, and how the data is collected from the different data sources. Specifically, we will obtain the data from three different data sources:\n",
    "1. [huggingface dataset](https://huggingface.co/datasets/Moaaz55/skin_cancer_questions_answers). This dataset is used for **joel pots explicar aqui**\n",
    "2. Self made audio dataset. This dataset is used for ...\n",
    "3. Wikipedia web scrapping information. This dataset is used for...\n",
    "\n",
    "In the next sections, we will discuss how the data is obtained to further insert them into the first zone of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a733d14",
   "metadata": {},
   "source": [
    "## Huggingface Dataset\n",
    "\n",
    "Explicar huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1191422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oriol/Documentos/MDS/ADSDB/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Limpieza completada:\n",
      "  Original: 798 filas\n",
      "  Limpio: 757 filas\n",
      "  Eliminadas: 41 filas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_json(\"hf://datasets/Moaaz55/skin_cancer_questions_answers/dataset.json\", lines=True)\n",
    "\n",
    "def limpiar_dataset(df, columna='Answer'):\n",
    "    # Convertir a string y limpiar\n",
    "    df_temp = df.copy()\n",
    "    df_temp[columna] = df_temp[columna].astype(str)\n",
    "    \n",
    "    # filter valid answers.\n",
    "    df_limpio = df_temp[\n",
    "        df_temp[columna].notna() &\n",
    "        (df_temp[columna].str.strip() != '') &\n",
    "        (df_temp[columna].str.strip() != 'nan') &\n",
    "        (df_temp[columna].str.strip() != 'None') &\n",
    "        (df_temp[columna].str.strip() != 'null') &\n",
    "        (df_temp[columna].str.len() > 10)  # MÃ­nimo 10 caracteres\n",
    "    ]\n",
    "    \n",
    "    print(f\" Limpieza completada:\")\n",
    "    print(f\"  Original: {len(df)} filas\")\n",
    "    print(f\"  Limpio: {len(df_limpio)} filas\")\n",
    "    print(f\"  Eliminadas: {len(df) - len(df_limpio)} filas\")\n",
    "    \n",
    "    return df_limpio\n",
    "\n",
    "\n",
    "df = limpiar_dataset(df)\n",
    "df = df.sample(n=100, random_state=42)\n",
    "df_text = df\n",
    "df_text = df.apply(lambda row: f\"Q: {row['Question']}\\nA: {row['Answer']}\\n\", axis=1)\n",
    "df_text\n",
    "with open(\"preguntas_respuestas.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(df_text.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
