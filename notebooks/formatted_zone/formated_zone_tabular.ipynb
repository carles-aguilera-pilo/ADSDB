{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5af850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe9618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acces_key_id = \"minioadmin\"\n",
    "secret_access_key = \"minioadmin\"\n",
    "minio_url = \"http://localhost:9000\"\n",
    "\n",
    "minio_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id = acces_key_id,\n",
    "    aws_secret_access_key = secret_access_key,\n",
    "    endpoint_url = minio_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526f8b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant fitxers tabulars:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant fitxers tabulars: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lesion_id      image_id diagnosis    dx_type   age     sex  \\\n",
      "0     HAM_0007418  ISIC_0031372        df  consensus  50.0    male   \n",
      "1     HAM_0004785  ISIC_0030788        nv  follow_up  60.0    male   \n",
      "2     HAM_0004585  ISIC_0032881        nv  consensus  55.0    male   \n",
      "3     HAM_0000086  ISIC_0028081        nv  follow_up  45.0  female   \n",
      "4     HAM_0004204  ISIC_0033772        nv  consensus  40.0  female   \n",
      "...           ...           ...       ...        ...   ...     ...   \n",
      "8007  HAM_0000593  ISIC_0031401       mel      histo  50.0    male   \n",
      "8008  HAM_0000420  ISIC_0026864        nv  follow_up  40.0    male   \n",
      "8009  HAM_0004821  ISIC_0031885        nv  follow_up  50.0    male   \n",
      "8010  HAM_0007400  ISIC_0027329        nv  follow_up  50.0  female   \n",
      "8011  HAM_0003157  ISIC_0031578     akiec      histo  65.0    male   \n",
      "\n",
      "         localization                   bbox  area_coverage  \n",
      "0     lower extremity  [235. 175. 368. 264.]       0.031661  \n",
      "1                back  [ 58.   0. 496. 420.]       0.502837  \n",
      "2             unknown  [189. 131. 357. 297.]       0.077996  \n",
      "3               trunk  [ 55.   0. 460. 448.]       0.459337  \n",
      "4             unknown  [115.  36. 431. 312.]       0.250387  \n",
      "...               ...                    ...            ...  \n",
      "8007             back  [ 83.  31. 544. 402.]       0.451004  \n",
      "8008            trunk  [127. 139. 278. 299.]       0.062787  \n",
      "8009  lower extremity  [285. 127. 405. 244.]       0.038380  \n",
      "8010  lower extremity  [182. 138. 333. 300.]       0.066922  \n",
      "8011  upper extremity  [ 92.  55. 582. 372.]       0.387570  \n",
      "\n",
      "[8012 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "bucket_origen = \"persistent-landing\"\n",
    "bucket_desti = \"formatted-zone\"\n",
    "prefix_origen = \"tabular/\"\n",
    "\n",
    "# Si saps els tipus esperats, pots definir-los aquí\n",
    "TIPUS_ESPERATS = {\n",
    "    \"lesion_id\": \"string\",\n",
    "    \"image_id\": \"string\",\n",
    "    \"diagnosis\": \"string\",\n",
    "    \"dx_type\": \"string\",\n",
    "    \"age\": \"float\",\n",
    "    \"sex\": \"string\",\n",
    "    \"localization\": \"string\",\n",
    "    \"bbox\": \"string\",\n",
    "    \"area_coverage\": \"float\"\n",
    "}\n",
    "\n",
    "# Funció de neteja\n",
    "def netejar_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Noms de columnes nets\n",
    "    df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "    #Forçar tipus\n",
    "    for col, tipus in TIPUS_ESPERATS.items():\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                if tipus == \"float\":\n",
    "                    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "                elif tipus == \"string\":\n",
    "                    df[col] = df[col].astype(\"string\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error convertint {col}: {e}\")\n",
    "\n",
    "    #Tractament de valors nuls\n",
    "    df = df.fillna(\"unknown\")\n",
    "\n",
    "    #Normalitzar valors de text\n",
    "    if \"sex\" in df.columns:\n",
    "        df[\"sex\"] = df[\"sex\"].str.lower().replace({\n",
    "            \"m\": \"male\", \"f\": \"female\", \"man\": \"male\", \"woman\": \"female\"\n",
    "        })\n",
    "\n",
    "    #Eliminar duplicats\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "#Processar tots els fitxers del bucket\n",
    "paginator = minio_client.get_paginator(\"list_objects_v2\")\n",
    "\n",
    "for page in paginator.paginate(Bucket=bucket_origen, Prefix=prefix_origen):\n",
    "    for obj in tqdm(page.get(\"Contents\", []), desc=\"Processant fitxers tabulars\"):\n",
    "        key = obj[\"Key\"]\n",
    "        filename = key.split(\"/\")[-1]\n",
    "\n",
    "        if not filename.lower().endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        # Llegir CSV des del bucket\n",
    "        response = minio_client.get_object(Bucket=bucket_origen, Key=key)\n",
    "        content = response[\"Body\"].read()\n",
    "        df = pd.read_csv(io.BytesIO(content), encoding=\"utf-8\")\n",
    "\n",
    "        # Netejar DataFrame\n",
    "        df_clean = netejar_dataframe(df)\n",
    "        df_clean = df_clean[~df_clean.isin([\"unknown\"]).any(axis=1)]  \n",
    "        \n",
    "        print(df)\n",
    "\n",
    "        # Convertir a Parquet\n",
    "        parquet_buffer = io.BytesIO()\n",
    "        df_clean.to_parquet(parquet_buffer, index=False)\n",
    "        parquet_buffer.seek(0)\n",
    "\n",
    "        # Pujar a formatted-zone\n",
    "        new_key = f\"tabular/{filename.replace('.csv', '.parquet')}\"\n",
    "        minio_client.put_object(\n",
    "            Bucket=bucket_desti,\n",
    "            Key=new_key,\n",
    "            Body=parquet_buffer\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7aa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
